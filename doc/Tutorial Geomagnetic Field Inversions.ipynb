{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138ee2d5",
   "metadata": {},
   "source": [
    "# Tutorial Geomagnetic Field Inversions\n",
    "This is a tutorial for using the Geomagnetic Field Inversions code written by Frenk Out, Liz van Grinsven, Monika Korte, and Lennart de Groot. This tutorial will guide you through the following process:\n",
    "1. Loading and Fitting data\n",
    "2. Starting the model\n",
    "    1. Initiating a FieldInversion class and add data\n",
    "    2. Run a time-dependent standard iterative inversion\n",
    "    3. Plotting results\n",
    "3. Sweeping through models to find optimal damping parameters (optional)\n",
    "4. Run an inversion at one time (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62daf56",
   "metadata": {},
   "source": [
    "### 0. Loading libraries\n",
    "This tutorial requires, besides geomagnetic_field_inversions, numpy, pandas, pathlib, matplotlib, and cartopy. The geomagnetic_field_inversions code consists of three files:\n",
    "1. StationData is a class that prepares geomagnetic field data to be inputted in FieldInversion later.\n",
    "2. FieldInversion is the main class where all calculations happen.\n",
    "3. plot_tools is a plotting module that helps to create frequently used plots in a easy way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "# Necessary for loading excel or csv files\n",
    "import pandas as pd\n",
    "# Necessary for correct path handling\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# Cartopy is only required for plotting world maps\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Our code\n",
    "from geomagnetic_field_inversions import plot_tools as plot_tools\n",
    "from geomagnetic_field_inversions import StationData\n",
    "from geomagnetic_field_inversions import FieldInversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288202b",
   "metadata": {},
   "source": [
    "## 1. Loading and Fitting data\n",
    "#### Set-up\n",
    "We will now proceed to loading and fitting the data. This is required to run the inversion later. The basic input for adding and fitting the data is latitude and longitude of each sample location. After the class is initiated, data can be added. This data can be inclination, declination, or intensity data, but also X, Y, Z, or H magnetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2aff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path to load and save files\n",
    "# path should be like: .../geomagnetic_field_inversions/doc\n",
    "path = Path().absolute()\n",
    "# location of our 'mock' dataset\n",
    "excel = pd.ExcelFile(path / 'first run_reversetime.xlsx')\n",
    "# the latitude and longitude of out 6 stations in degrees\n",
    "lat = [0.1, 35.0, 8.0, 35.9, 5.0, 60.7]\n",
    "lon = [336.7, 140.0, 121.0, 243.0, 73.0, 336.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7d9ab",
   "metadata": {},
   "source": [
    "#### *StationData and add_data*\n",
    "Now that we have set the groundwork, we can proceed to adding and fitting the individual datasets. All data belonging to the same location can be added to the same class. First we initiate a class for the station using its latitude and longitude. After that, we add data belonging to that station separately (from the spreadsheet) add expected error and finally fit a line through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34330f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by initializing a new class using latitude and longitude of the station\n",
    "oda_2000 = StationData(lat[2], lon[2])\n",
    "\n",
    "# We inputted time as kiloyears, so our timefactor is 1000\n",
    "oda_2000.add_data('int', (pd.read_excel(excel, 'Oda_2000').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "oda_2000.add_data('inc', (pd.read_excel(excel, 'Oda_2000').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "oda_2000.add_data('dec', (pd.read_excel(excel, 'Oda_2000').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "\n",
    "# The fitting method fits a line through the data points\n",
    "# Since we specified output, we we will see the resulting graphs\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "oda_2000.fitting(order=[8, 3, 3], smoothing=[None, 50, 100], method=['polyfit', 'USpline', 'USpline'], ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we fit the rest, but do not show the output\n",
    "# By providing output='YOUR_PATH_NAME' you can observe the plots\n",
    "valet_1989 = StationData(lat[0], lon[0])\n",
    "valet_1989.add_data('int', (pd.read_excel(excel, 'Valet_1989').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "valet_1989.add_data('inc', (pd.read_excel(excel, 'Valet_1989').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_1989.add_data('dec', (pd.read_excel(excel, 'Valet_1989').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_1989.fitting()\n",
    "\n",
    "haneda_2020 = StationData(lat[1], lon[1])\n",
    "haneda_2020.add_data('int', (pd.read_excel(excel, 'Haneda_2020').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "haneda_2020.add_data('inc', (pd.read_excel(excel, 'Haneda_2020').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "haneda_2020.add_data('dec', (pd.read_excel(excel, 'Haneda_2020').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "haneda_2020.fitting()\n",
    "\n",
    "valet_1988 = StationData(lat[3], lon[3])\n",
    "valet_1988.add_data('int', (pd.read_excel(excel, 'Valet_1988').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "valet_1988.add_data('inc', (pd.read_excel(excel, 'Valet_1988').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_1988.add_data('dec', (pd.read_excel(excel, 'Valet_1988').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_1988.fitting(order=[3, 14, 10], smoothing=[0.02, None, None], method=['USpline', 'polyfit', 'polyfit'])\n",
    "\n",
    "valet_2014 = StationData(lat[4], lon[4])\n",
    "valet_2014.add_data('int', (pd.read_excel(excel, 'Valet_2014').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "valet_2014.add_data('inc', (pd.read_excel(excel, 'Valet_2014').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_2014.add_data('dec', (pd.read_excel(excel, 'Valet_2014').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "valet_2014.fitting(order=[8, 8, 5])\n",
    "\n",
    "channell_2000 = StationData(lat[5], lon[5])\n",
    "channell_2000.add_data('int', (pd.read_excel(excel, 'Channell_2000').iloc[:, [4, 5]].dropna().T.values.tolist()), 1000, error=1)\n",
    "channell_2000.add_data('inc', (pd.read_excel(excel, 'Channell_2000').iloc[:, [0, 1]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "channell_2000.add_data('dec', (pd.read_excel(excel, 'Channell_2000').iloc[:, [2, 3]].dropna().T.values.tolist()), 1000, error=np.radians(10))\n",
    "channell_2000.fitting(order=[15, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13342c69",
   "metadata": {},
   "source": [
    "Our data is now ready to be used in the next step\n",
    "- Note: the warning for declinations and/or inclinations falling of range can be ignored most of the times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc8260",
   "metadata": {},
   "source": [
    "## 2. Starting the model\n",
    "### 2. Initiate a FieldInversion class and add data\n",
    "#### *FieldInversion*\n",
    "The `FieldInversion`-class is the 'location' where we will perform all calculations. We start a FieldInversion class by calling\n",
    "- `MyInstance = FieldInversion(time_array=np.linspace(3000, 17000, 15), verbose=True)` \n",
    "\n",
    "The time_array contains the timesteps over which we want to invert our data; the verbosity flag helps us to understand what is going on in the code.\n",
    "\n",
    "More parameters can be changed, but we will not do that for now.\n",
    "&rarr; For more info about other parameters of this class, type:\n",
    "`FieldInversion?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input modeled time array; from 3000 to 17000 with steps of 1000 yr\n",
    "test_inv = FieldInversion(time_array = np.linspace(0, 20000, 21), verbose=True)\n",
    "\n",
    "# FieldInversion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091a444",
   "metadata": {},
   "source": [
    "#### *add_data*\n",
    "After we have initiated the `FieldInversion`-class, we add our data by simply calling the `add_data`-method and adding the fitted classes from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inv.add_data(valet_1989)\n",
    "test_inv.add_data(haneda_2020)\n",
    "test_inv.add_data(oda_2000)\n",
    "test_inv.add_data(valet_1988)\n",
    "test_inv.add_data(valet_2014)\n",
    "test_inv.add_data(channell_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54174f63",
   "metadata": {},
   "source": [
    "The output tells us that the different datatypes are successfully added to the `FieldInversion`-class. Additionally, the coordinates of the sample stations are translated into a geocentric reference frame, since they are given in a geodetic reference frame. If you want to know more about this, type `FieldInversion?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cb13c",
   "metadata": {},
   "source": [
    "### B. Run a time-dependent standard iterative inversion\n",
    "After we have set up the class, we can proceed to the geomagnetic field inversion.\n",
    "#### *prepare_inversion*\n",
    "First we have to prepare all matrices before execution. For that purpose we need two parameters:\n",
    "- spatial_df: the spatial damping factor\n",
    "- temporal_df: the temporal damping factor\n",
    "\n",
    "For illustrative purposes, we set these damping factors to 3e-10 and 1e-2 respectively. Normally you would have to investigate which combination of damping parameters is best (see section 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039470e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inv.prepare_inversion(spatial_df = 3e-10, temporal_df = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22012e26",
   "metadata": {},
   "source": [
    "#### *run_inversion*\n",
    "Now we have prepared everything for the inversion. We can now proceed to starting the iterative inversion by using the `run_inversion`-method. This method requires at least a starting model. We will use a starting model with where only $g_1^0$ has a value of -30000.\n",
    "\n",
    "we also set the maximum amount of iterations to 30, and the intensity multiplier to 10.000. This multiplier scales our intensity better to realistic values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd3e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# our starting model should be as long as the number of gaussian coefficients, i.e. 15.\n",
    "x0 = np.zeros(15)\n",
    "x0[0] = -30000\n",
    "test_inv.run_inversion(x0, max_iter=10, int_mult=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d64558",
   "metadata": {},
   "source": [
    "After each iteration, the rms residual is shown. Already after 5 iterations the residual does not change much\n",
    "\n",
    "#### *save_spherical_coefficients*\n",
    "We will now proceed to saving our final coefficients and residuals by inputting a path and name to save our files. This will create a *Tutorial_residual.csv*-file containing all residuals after each timestep. Additionally, we save the final gaussian coefficients of the final iteration, per timestep, unsplined. The gaussian coefficients are stored degree-wise, so: $g_1^0$, $g_1^1$, $h_1^1$, $g_2^0$, $g_2^1$, $h_2^1$, $g_2^2$, $h_2^2$, etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903ad52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_inv.save_spherical_coefficients(path / 'output', file_name='Tutorial', save_residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d22769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(path / 'output' / 'Tutorial_residual.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142d9ef",
   "metadata": {},
   "source": [
    "### C. Plotting Results\n",
    "After running the inversion, we will obtain plots of the results to investigate what is going on in our model. For that purpose, we will plot residuals, powerspectra, coefficients, and magnetic field values through time.\n",
    "\n",
    "#### residuals plots\n",
    "by calling `plot_tools.plot_residual` we can easily create a plot that shows the residuals of the various datatypes per iteration. The figure shows in this case that after 4 or 5 iterations the residual seems stable. The angle still fluctuates a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by plotting the rms of various types per iteration\n",
    "# start a figure\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Residuals')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Relative residual')\n",
    "# make a call to the plotting library, input ax and our FieldInversion instance\n",
    "ax = plot_tools.plot_residuals(ax, test_inv)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bd524",
   "metadata": {},
   "source": [
    "#### powerspectra (to be updated)\n",
    "The `plot_tools.plot_powerspectrum` allows the plotting of the powerspectrum of the gaussian coefficients. The default option is to plot the energy 'stored' in each degree together with its temporal variance.\n",
    "\n",
    "It is also possible to plot the individual gaussian coefficients with its temporal variance over certain time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start figure\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Powerspectrum')\n",
    "ax.set_xlabel('Spherical degree l')\n",
    "ax.set_ylabel('Power')\n",
    "# make a call to the plotting library\n",
    "ax = plot_tools.plot_powerspectrum(ax, test_inv)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# now we plot the mean gaussian coefficients through a time interval with std\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Gaussian coefficients')\n",
    "ax.set_xlabel('# gaussian coefficient')\n",
    "ax.set_ylabel('nT')\n",
    "ax = plot_tools.plot_powerspectrum(ax, test_inv, power=False, plot_time=np.arange(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb69af3",
   "metadata": {},
   "source": [
    "#### gaussian coefficients\n",
    "By using `plot_tools.plot_gaussian` we can plot the gaussian coefficients through time. It plots all gaussian coefficients of the same degree at once, but we could also decide to define yourself which coefficients to plot by setting `degree, order, and h_bool` (see `plot_tools.plot_gaussian?`). It defaults to using the coefficients calculated in the last iteration, but we could choose otherwise by setting plot_iter to something else than -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb455abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Gaussian coefficients through time')\n",
    "ax.set_xlabel('Time (yr)')\n",
    "ax.set_ylabel('Value (nT)')\n",
    "# we only want to plot gaussian coefficients of degree 1\n",
    "ax = plot_tools.plot_gaussian(ax, test_inv, plot_degree=1)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e082667",
   "metadata": {},
   "source": [
    "#### forward calculations\n",
    "After calculation of the gaussian coefficients, we plot their effect on a worldmap and on one location. For the worldmap, we define 3 axes and choose a projection. We choose a time we want to plot and set contourlevels with optional keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc01ac0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set three axes and apply a Robinson world projection\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(20, 45), subplot_kw={'projection': ccrs.Robinson()})\n",
    "# set some keyword arguments for the plotting, for all options see plot_tools.plot_world?\n",
    "plot_kw = {'level_int': np.arange(1000, 3000, 100), 'levelf_int': np.arange(1000, 3000, 100)}\n",
    "# call the function; input axes and inversion class, but also wished projection, plot time, and optional plotting keywords\n",
    "axes = plot_tools.plot_world(axes, test_inv, projection=ccrs.PlateCarree(), plot_time=0, plot_kw=plot_kw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724691c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sheet in [valet_1989, haneda_2020, oda_2000, valet_1988, valet_2014, channell_2000]:\n",
    "    print(sheet)\n",
    "    fig, axes = plt.subplots(len(sheet.types), 1, figsize=(8, 4*len(sheet.types)))\n",
    "    axes = plot_tools.compare_loc(axes, test_inv, sheet)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead47148",
   "metadata": {},
   "source": [
    "## 3. Sweeping through models to find optimal damping parameters\n",
    "Normally we do not have the optimal damping parameters yet, which is why we will have to search for them **now**. \n",
    "We will start a new class and add all our data, then we will sweep through a range of spatial and temporal damping parameters. By plotting model size versus residuals, we will find the best fitting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set class and add data\n",
    "sweep_inv = FieldInversion(time_array = np.linspace(3000, 17000, 15))\n",
    "\n",
    "sweep_inv.add_data(valet_1989)\n",
    "sweep_inv.add_data(haneda_2020)\n",
    "sweep_inv.add_data(oda_2000)\n",
    "sweep_inv.add_data(valet_1988)\n",
    "sweep_inv.add_data(valet_2014)\n",
    "sweep_inv.add_data(channell_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b53437",
   "metadata": {},
   "source": [
    "#### *sweep_damping*\n",
    "This method enables us to sweep through the parameters, it needs:\n",
    "- spatial_range: the range of spatial damping parameters to be tested\n",
    "- temporal_range: the range of temporal damping parameters to be tested\n",
    "- x0: starting model of gaussian coefficients\n",
    "\n",
    "Result can be saved to a folder with the optional dictionary save_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_range = np.logspace(-12, -8, 5)\n",
    "temporal_range = np.logspace(0, 10, 5)\n",
    "x0 = np.zeros(15)\n",
    "x0[0] = -30000\n",
    "\n",
    "sweep_inv.sweep_damping(x0, spatial_range, temporal_range, save_kwargs={'basedir': path / 'output', 'save_residual': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638096eb",
   "metadata": {},
   "source": [
    "After performing the calculations, we can plot the results of the damping parameters with `plot_tools.plot_sweep`. For the first plot we hold temporal damping; in the second plot we hold spatial damping. The best model would be the model that produces a low residual and a small model size (=norm of the gaussian coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot residual vs norm of the model\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Finding optimal damping')\n",
    "ax.set_xlabel('model norm')\n",
    "ax.set_ylabel('residual')\n",
    "# call function to plot lines\n",
    "ax = plot_tools.plot_sweep(ax, spatial_range, temporal_range, plot_spatial=True,\n",
    "                           basedir=path / 'output')\n",
    "# define colors and a colorbar\n",
    "norm = mpl.colors.Normalize(vmin=np.log10(temporal_range[0]), vmax=np.log10(temporal_range[-1]))\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlBu', norm=norm)\n",
    "plt.colorbar(sm, label='log10 temporal damping')\n",
    "plt.show()\n",
    "\n",
    "# now we hold the spatial damping parameter\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Finding optimal damping')\n",
    "ax.set_xlabel('model norm')\n",
    "ax.set_ylabel('residual')\n",
    "ax = plot_tools.plot_sweep(ax, spatial_range, temporal_range, plot_spatial=False,\n",
    "                           basedir=path / 'output')\n",
    "norm = mpl.colors.Normalize(vmin=np.log10(spatial_range[0]), vmax=np.log10(spatial_range[-1]))\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlBu', norm=norm)\n",
    "plt.colorbar(sm, label='log10 spatial damping')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bc01c",
   "metadata": {},
   "source": [
    "#### conclusion\n",
    "A spatial damping factor of 1e-9 seems to be best; it results in both a low residual and small gaussian coefficients. For the temporal damping factor, it is slightly harder to judge. For now we will assume a temporal damping factor of 1e6. These damping parameters could then be used in the main model (see section 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ac87c",
   "metadata": {},
   "source": [
    "## 4. Run an inversion at one time\n",
    "The code does also work for one timestep. However, to execute the inversion we have to call `run_inversion_notime` instead of `run_inversion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_inv = FieldInversion(time_array = [6000])\n",
    "one_inv.add_data(valet_1989)\n",
    "one_inv.add_data(haneda_2020)\n",
    "one_inv.add_data(oda_2000)\n",
    "one_inv.add_data(valet_1988)\n",
    "one_inv.add_data(valet_2014)\n",
    "one_inv.add_data(channell_2000)\n",
    "one_inv.prepare_inversion(spatial_df = 1e-10, temporal_df = 0)\n",
    "x0 = np.zeros(15)\n",
    "x0[0] = -30000\n",
    "one_inv.run_inversion_notime(x0, max_iter=30, int_mult=1e4)\n",
    "one_inv.save_spherical_coefficients(path / 'output', save_residual=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Residuals')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Relative residual')\n",
    "ax = plot_tools.plot_residuals(ax, one_inv)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Powerspectrum')\n",
    "ax.set_xlabel('Spherical degree l')\n",
    "ax.set_ylabel('Energy (nT$^2$)')\n",
    "ax = plot_tools.plot_powerspectrum(ax, one_inv)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
