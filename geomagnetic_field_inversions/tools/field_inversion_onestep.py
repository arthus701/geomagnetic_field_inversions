import numpy as np
from scipy.interpolate import BSpline, interp1d
import scipy.linalg as scl
import pandas as pd
from typing import Union, Final
from pathlib import Path

from ..data_prep import StationData
from ..forward_modules import frechet, fwtools, rejection
from ..tools import geod2geoc as g2g


class FieldInversionNoTime:
    """
    Calculates geomagnetic field coefficients at one time based on inputted
    data and damping parameters using the approach of Korte et al. (????)
    """

    def __init__(self,
                 time: float,
                 maxdegree: int = 3,
                 r_model: float = 6371.2,
                 geodetic: bool = True,
                 verbose: bool = False
                 ) -> None:
        """
        Initializes the Field Inversion class
        
        Parameters
        ----------
        time
            time to apply inversion to
        maxdegree
            maximum order for spherical harmonics model, default 3
        r_model
            where the magnetic field is modeled (km distance from core)
        geodetic
            boolean specifying whether to use a geodetic coordinate frame. If
            True, geodetic coordinate frame is used and recalculated into a
            geocentric one. Otherwise, a geocentric frame is used.
            Default is geodetic (True)
        verbose
            Verbosity flag, defaults to False
        """
        # basic parameters
        self._SPL_DEGREE: Final[int] = 3

        # input parameters
        self.time = time
        self.maxdegree = maxdegree
        self.r_model = r_model
        self.geodetic = geodetic
        self.verbose = verbose

        # derived properties
        self.data_array = np.empty(0)
        self.error_array = np.empty(0)
        self.accept_matrix = np.empty(0)
        self.types = []
        self.sc = 0  # station count
        self.types_ready = False
        self.types_sorted = np.empty(0)
        self.count_type = np.zeros(7)
        self.station_coord = np.zeros((0, 3))
        self.gcgd_conv = np.zeros((0, 2))
        self.damp_matrix = np.empty(0)
        self.spat_fac = np.empty(0)  # contains damping factors
        self.temp_fac = np.empty(0)
        self.spat_norm = np.empty(0)
        self.temp_norm = np.empty(0)
        self.spat_ddt = 0
        self.temp_ddt = 0
        self.splined_gh = np.empty(0)
        self.station_frechet = np.empty(0)
        self.res_iter = np.empty(0)
        self.unsplined_iter_gh = []
        self.dcname = []  # contains name of stations
        self.rejected = np.empty(0)

    @property
    def maxdegree(self):
        return self._maxdegree

    @maxdegree.setter
    def maxdegree(self, degree: int):
        # determines the maximum number of spherical coefficients
        self._nm_total = int((degree+1)**2 - 1)
        self._maxdegree = int(degree)
        self.matrix_ready = False

    def add_data(self,
                 data_class: StationData,
                 error_interp: str = 'linear'
                 ) -> None:
        """
        Adds data generated by the Station_data class

        Parameters
        ----------
        data_class
            instance of the Station_data class. Only added if it matches the
            time_array set in __init__
        error_interp
            string specifying interpolation of inputted error to time_array
            according to documentation of scipy.interpolate.interp1d

        Creates or modifies
        -------------------
        self.data_array
            contains the measurements per site
            size= # datatypes (floats)
        self.error_array
            contains the error in measurements per site
            size= # datatypes (float)
        self.types
            contains the type of all data in one long list
            size= # datatypes (integers)
        self.station_coord
            contains the colatitude, longitude, and radius of station
            size= (# datatypes, 3) (floats)
        self.gcgd_conv
            contains conversion factors for geodetic to geocentric conversion
            of magnetic components mx/dx and mz/dz
            size= (# datatypes, 2) (floats)
        self.types_ready
            boolean indicating if datatypes (self.types) are logically sorted
        """
        # translation datatypes
        typedict = {"x": 0, "y": 1, "z": 2, "hor": 3,
                    "int": 4, "inc": 5, "dec": 6}
        if isinstance(data_class, StationData):
            self.sc += 1
            # set up matrices
            data_entry = np.zeros(len(data_class.types))
            error_entry = np.ones(len(data_class.types))
            types_entry = []
            name = data_class.__name__
            for c, types in enumerate(data_class.types):
                # check coverage data timevector begin
                if data_class.data[c][0][0] > self.time\
                        or data_class.data[c][0][-1] < self.time:
                    print(f'{types} of {name} not covering time')
                else:
                    if self.verbose:
                        print(f'Adding {types}-type')
                    # temporary data and error storage
                    temp_d = data_class.fit_data[c](self.time)
                    temp_e = data_class.data[c][2]
                    if types == 'inc' or types == 'dec':
                        # transform incl/decl data to radians
                        temp_d = np.radians(temp_d)
                        temp_e = np.radians(temp_e)

                    # add to data array
                    data_entry[c] = temp_d
                    # sample errors for time_array
                    f = interp1d(data_class.data[c][0], temp_e,
                                 kind=error_interp)
                    error_entry[c] = f(self.time)
                    # count occurrence datatype and add to list
                    types_entry.append(typedict[types])

            # change coordinates from geodetic to geocentric if required
            if self.geodetic:
                if self.verbose:
                    print(f'Coordinates are geodetic,'
                          ' translating to geocentric coordinates.')
                lat_geoc, r_geoc, cd, sd = g2g.latrad_in_geoc(
                    np.radians(data_class.lat), data_class.height)
                station_entry = np.array([0.5*np.pi - lat_geoc,
                                          np.radians(data_class.lon),
                                          r_geoc])
            else:
                if self.verbose:
                    print(f'Coordinates are geocentric,'
                          ' no translation required.')
                cd = 1.  # this will not change dx and dz when forming frechet
                sd = 0.
                station_entry = np.array([np.radians(90-data_class.lat),
                                          np.radians(data_class.lon),
                                          6371.2+data_class.height*1e-3])

            # add data to attributes of the class if all is fine
            if self.verbose:
                print(f'Data of {name} is added to class')
            self.dcname.append(name)
            self.data_array = np.concatenate((self.data_array, data_entry))
            self.error_array = np.concatenate((self.error_array, error_entry))
            self.types.append(types_entry)  # is now one long list
            self.station_coord = np.vstack((self.station_coord, station_entry))
            self.gcgd_conv = np.vstack((self.gcgd_conv, np.array([cd, sd])))
            self.types_ready = False
        else:
            raise Exception('data_class is not an instance of Station_Data')

    def prepare_inversion(self) -> None:
        """
        Function to prepare matrices for the one timestep inversion

        Creates or modifies
        -------------------
        self.station_frechet
            contains frechet matrix per location
            size= ((# stations x 3), nm_total) (floats)
        self.spat_fac, self.temp_fac
            contains the damping elements dependent on degree
             size= nm_total (floats) (see damp_types.py)
        self.matrix_ready
            indicates whether all matrices have been formed (boolean)
        self.types_ready
            boolean indicating if datatypes (self.types) are logically sorted
        """
        # print warning
        if self._nm_total >= len(self.data_array):
            print('The spherical order of the model is too high (variables:'
                  f' {self._nm_total} vs data: {len(self.data_array)}), '
                  f'decrease maxdegree to a lower value.')

        # order datatypes in a more straightforward way
        if not self.types_ready:
            self.types_sorted = []
            for nr, stat in enumerate(self.types):
                for datum in stat:  # datum is 0 to 6
                    self.types_sorted.append(7*nr + datum)
            self.types_sorted = np.array(self.types_sorted)
            self.types_ready = True

        # calculate frechet dx, dy, dz for all stations
        if self.verbose:
            print('Calculating Schmidt polynomials and FrÃ©chet coefficients')
        self.station_frechet = frechet.frechet_basis(
            self.station_coord, self._maxdegree)
        # geocentric correction
        dx, dz = g2g.frechet_in_geoc(
            self.station_frechet[:self.sc],
            self.station_frechet[2*self.sc:],
            self.gcgd_conv[:, 0], self.gcgd_conv[:, 1])
        self.station_frechet[:self.sc] = dx
        self.station_frechet[2*self.sc:] = dz

        self.matrix_ready = True
        if self.verbose:
            print('Calculations finished')

    def run_inversion(self,
                      x0: np.ndarray,
                      max_iter: int = 10,
                      rej_crits: np.ndarray = None,
                      path: Path = None
                      ) -> None:
        """
        Runs the iterative inversion

        Parameters
        ----------
        x0
            starting model gaussian coefficients, should have length:
            (spherical_order + 1)^2 - 1
        max_iter
            maximum amount of iterations
        rej_crits
            Optional rejection criteria. Should be a length 7 array containing
            rejection criteria for x, y, z, hor, int, incl, and decl
            components. inc/dec in radians!
        path
            path to location where to save normal_eq for calculating optional
            covariance and resolution matrix.
            If not provided, matrix are not saved. See tools/stdev.py

        Creates or modifies
        -------------------
        self.res_iter
             contains the RMS per datatype and the sum of all types
             size= 8 (floats)
        self.unsplined_iter_gh
            contains the BSpline function to unspline Gauss coeffs at
            requested time for every iteration
            size= # iterations (BSpline functions)
        """
        # TODO: add uncertainty and data rejection
        if not self.matrix_ready:
            raise Exception('Matrices have not been prepared. '
                            'Please run prepare_inversion first.')
        if rej_crits is not None:
            self.rejected = np.zeros(max_iter)
        # initiate array counting residual per type
        self.res_iter = np.zeros((max_iter+1, 8))
        # initiate splined values with starting model
        if self.verbose:
            print('Setting up starting model')
        self.unsplined_iter_gh = np.zeros((max_iter+1, self._nm_total))
        if x0.ndim == 1 and len(x0) == self._nm_total:
            self.unsplined_iter_gh[0] = x0
        else:
            raise Exception(f'x0 has incorrect shape: {x0.shape}. \n'
                            f'It should have shape ({self._nm_total},)')
        # initiate accept_matrix (default accept all) + diagonal damping matrix
        self.accept_matrix = np.ones(len(self.types_sorted))
        for it in range(max_iter):  # start outer iteration loop
            if self.verbose:
                print(f'Start iteration {it+1}')
            # Calculate frechet and residual matrix for all times
            # and apply time constraint (time_cover)
            if self.verbose:
                print('Create forward and residual observations')
            forwobs_matrix = fwtools.forward_obs(
                self.unsplined_iter_gh[it][np.newaxis, :],
                self.station_frechet, reshape=False)
            frech_matrix = frechet.frechet_types(
                self.station_frechet, self.types_sorted, forwobs_matrix)
            forwobs_matrixrs = forwobs_matrix.T.flatten()[self.types_sorted]
            res_matrix = fwtools.residual_obs(
                forwobs_matrixrs, self.data_array, self.types_sorted)

            # reject data if inputted through accept_matrix
            use_data_boolean = self.accept_matrix
            if rej_crits is not None:
                self.accept_matrix = rejection.reject_data(
                    res_matrix, self.types_sorted, rej_crits)
                rejected = len(self.accept_matrix.flatten())\
                           - sum(self.accept_matrix.flatten())
                self.rejected[it] = rejected
                if self.verbose:
                    print(f'{rejected} datapoints rejected')
                use_data_boolean = self.accept_matrix

            # apply rejection and time constraint to matrices
            frech_matrix *= np.repeat(use_data_boolean[:, np.newaxis],
                                      self._nm_total, axis=1)
            res_matrix *= use_data_boolean
            res_weight = res_matrix / self.error_array
            # sum residuals
            self.count_type = np.zeros(7)
            type06 = self.types_sorted % 7
            for i in range(7):
                self.count_type[i] = np.sum(
                    np.where(type06 == i, use_data_boolean.T, 0))
            self.res_iter[it] = fwtools.residual_type(
                res_weight, self.types_sorted, self.count_type)

            # create time dependent matrix and vector
            if self.verbose:
                print('Start formation matrices')
            rhs_matrix = np.matmul(frech_matrix.T / self.error_array,
                                   res_weight)
            # Apply B-Splines straight away (much easier)
            normal_eq = np.matmul(frech_matrix.T / self.error_array**2,
                                  frech_matrix)

            # solve the equations
            if self.verbose:
                print('Solve equations')
            update = scl.solve(normal_eq, rhs_matrix)
            self.unsplined_iter_gh[it+1] = self.unsplined_iter_gh[it] + update

            if self.verbose:
                print('Residual is %.2f' % self.res_iter[it, 7])
            # residual after last iteration
            if it == max_iter - 1:
                if self.verbose:
                    print('Calculate residual last iteration')
                forwobs_matrix = fwtools.forward_obs(
                    self.unsplined_iter_gh[it][np.newaxis, :],
                    self.station_frechet, reshape=False)
                forwobs_matrixrs = forwobs_matrix.T.flatten(
                    )[self.types_sorted]
                res_matrix = fwtools.residual_obs(
                    forwobs_matrixrs, self.data_array, self.types_sorted)
                res_matrix *= use_data_boolean
                res_weight = res_matrix / self.error_array
                # sum residuals
                self.res_iter[it+1] = fwtools.residual_type(
                    res_weight, self.types_sorted, self.count_type)
                if self.verbose:
                    print('Residual is %.2f' % self.res_iter[it+1, 7])
                if path is not None:
                    if self.verbose:
                        print('Saving matrix')
                    np.save(path / 'normal_eq', normal_eq)
                if self.verbose:
                    print('Finished inversion')

    def save_coefficients(self,
                          basedir: Union[Path, str] = '.',
                          file_name: str = 'coeff',
                          save_iterations: bool = True,
                          save_residual: bool = False,
                          rejection_report: bool = False,
                          ) -> None:
        """
        Save the Gauss coefficients

        Parameters
        ----------
        basedir
            path where files will be saved
        file_name
            optional name to add to files
        save_iterations
            boolean indicating whether to save coefficients after
            each iteration. Is saved with the following shape:
             (# iterations, nm_total)
        save_residual
            boolean indicating whether to save the residuals
        rejection_report
            boolean indicating whether to store a rejection report showing
            which data has been rejected.
        """
        dict_types = ['x', 'y', 'z', 'hor', 'int', 'incl', 'decl']
        # save residual
        if save_residual:
            residual_frame = pd.DataFrame(
                self.res_iter, columns=['res x', 'res y', 'res z', 'res hor',
                                        'res int', 'res incl', 'res decl',
                                        'res total'])
            residual_frame.to_csv(basedir / f'{file_name}_residual.csv',
                                  sep=';')
        if rejection_report:
            f = open(basedir / f'{file_name}_reject.txt', 'w')
            row = 0
            for n, name in enumerate(self.dcname):
                f.write(f'Station {name}, {self.station_coord[n]} \n')
                for types in self.types[n]:
                    datarow = self.accept_matrix[row]
                    if np.sum(datarow) != len(datarow):
                        f.write(f'{dict_types[types]}: {self.time} \n')
                    row += 1
            f.close()
        if save_iterations:
            np.save(basedir / f'{file_name}_all.npy', self.unsplined_iter_gh)
        else:
            np.save(basedir / f'{file_name}_final.npy',
                    self.unsplined_iter_gh[-1])
